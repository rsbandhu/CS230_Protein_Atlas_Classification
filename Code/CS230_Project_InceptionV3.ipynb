{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.misc as misc\n",
    "import utils\n",
    "import os\n",
    "import numpy as np\n",
    "from models.Inception_V3_R1.data_loader import Dataloader\n",
    "import models.Inception_V3_R1.net as net\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inception_v3 = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating the model from the torch site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3 = models.inception_v3(pretrained=True)\n",
    "for param in inception_v3.parameters():\n",
    "    param.requires_grad = False\n",
    "#inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BasicConv2d(\n",
      "  (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), BasicConv2d(\n",
      "  (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Linear(in_features=768, out_features=1000, bias=True)]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features = list(inception_v3.fc())\n",
    "#features = []\n",
    "#vgg19.classifier = torch.nn.Sequential(*features)\n",
    "#vgg19\n",
    "features1 = list(inception_v3.AuxLogits.children())\n",
    "\n",
    "features2 = list(inception_v3.fc.children())\n",
    "print(features1)\n",
    "print(features2)\n",
    "features = []\n",
    "inception_v3.fc = nn.Sequential(*features)\n",
    "inception_v3.fc\n",
    "inception_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all the images (resized to 299 X 299 and normalized to 0 mean and stddev =1 ) through the Inception-V3 pretrained network except the final FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bony/Deep_Learning_Stanford_CS230/Project/Code\n",
      "/home/bony/Deep_Learning_Stanford_CS230/Project/Data/train_224\n",
      "train\n",
      "datatype is train\n",
      "image id count =  31072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'00070df0-bbc3-11e8-b2bc-ac1f6b6435d0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "print(cur_dir)\n",
    "json_path = os.path.join(cur_dir,'models/Inception_V3_R1/params.json')\n",
    "params = utils.Params(json_path)\n",
    "data_loader = Dataloader(params)\n",
    "\n",
    "labels_dict = data_loader.load_labels(\"train\", params)\n",
    "image_dict = data_loader.load_data(\"train\", params)\n",
    "img_count = len(image_dict)\n",
    "\n",
    "key_list = []\n",
    "for item in image_dict:\n",
    "    key_list.append(item)\n",
    "key_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.cuda = torch.cuda.is_available()\n",
    "\n",
    "inception_v3_eval = inception_v3.eval().cuda() if params.cuda else inception_v3.eval()\n",
    "\n",
    "image_feature_dict = {}\n",
    "img_count =0\n",
    "t0 = time.time()\n",
    "\n",
    "for img_id in key_list:\n",
    "\n",
    "    #img_id = data_loader.get_random_image_id(\"train\", params)\n",
    "    input_img = data_loader.load_single_image(\"train\", params, img_id).cuda()\n",
    "    inception_v3_eval_out = inception_v3_eval(input_img)\n",
    "    output = inception_v3_eval_out.cpu().numpy()\n",
    "    image_feature_dict[img_id] = output\n",
    "    \n",
    "    if (img_count % 500 == 0):\n",
    "        print(img_count, time.time() -t0)\n",
    "        t0 = time.time()\n",
    "    img_count += 1\n",
    "\n",
    "print('done preprocessing image for inception net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37203035, 0.09217899, 0.27023485, ..., 0.00871159, 0.06991827,\n",
       "        0.03201964]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = inception_v3_eval_out.cpu().numpy()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bony/Deep_Learning_Stanford_CS230/Project/Code\n",
      "/home/bony/Deep_Learning_Stanford_CS230/Project/Data/train\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "print(cur_dir)\n",
    "json_path = os.path.join(cur_dir,'models/Inception_V3_R1/params.json')\n",
    "model_dir = os.path.join(cur_dir, 'models/Inception_V3_R1')\n",
    "params = utils.Params(json_path)\n",
    "data_loader = Dataloader(params)\n",
    "labels_dict = data_loader.load_labels(\"train\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da5d5f3c-bba4-11e8-b2ba-ac1f6b6435d0 a21f3602-bbba-11e8-b2ba-ac1f6b6435d0\n",
      "image count =  31072\n",
      "minibatch_size  =  16\n",
      "num_epochs =  100\n",
      "features_in  =  2048\n",
      "num_batches  =  1942\n",
      "learning rate =  0.0001\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the images for training \n",
    "key_list = []\n",
    "for key in image_feature_dict:\n",
    "    key_list.append(key)\n",
    "np.random.shuffle(key_list)\n",
    "print(key_list[0], key_list[20])\n",
    "\n",
    "\n",
    "\n",
    "# Define some parameters\n",
    "image_count = len(labels_dict)\n",
    "minibatch_size = params.batch_size\n",
    "num_epochs = params.num_epochs\n",
    "features_in = params.features_in\n",
    "channels = 3    \n",
    "\n",
    "num_batches = (image_count +1) // params.batch_size\n",
    "\n",
    "print(\"image count = \", image_count)\n",
    "print(\"minibatch_size  = \", minibatch_size)\n",
    "print(\"num_epochs = \", num_epochs)\n",
    "print(\"features_in  = \", features_in)\n",
    "print(\"num_batches  = \", num_batches)\n",
    "print(\"learning rate = \", params.learning_rate)\n",
    "\n",
    "batch_data = torch.zeros([minibatch_size, features_in], dtype=torch.float32)\n",
    "batch_labels = torch.zeros([minibatch_size, 28], dtype=torch.float32)\n",
    "\n",
    "# Check if GPU is cuda capable\n",
    "cuda_present = torch.cuda.is_available()\n",
    "\n",
    "#Instantiate the model, loss fn, Optimizer\n",
    "if cuda_present:\n",
    "    model = net.Net(params).cuda()\n",
    "else:\n",
    "    model = net.Net(params)\n",
    "optimizer = optim.Adam(model.parameters(), lr= params.learning_rate)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************\n",
      " Epoch =  0 \n",
      "\n",
      "Batch #:0, training cost = 0.6962584257125854\n",
      "Batch #:200, training cost = 0.2033204883337021\n",
      "Batch #:400, training cost = 0.15681171417236328\n",
      "Batch #:600, training cost = 0.14521929621696472\n",
      "Batch #:800, training cost = 0.15073177218437195\n",
      "Batch #:1000, training cost = 0.17286698520183563\n",
      "Batch #:1200, training cost = 0.16172567009925842\n",
      "Batch #:1400, training cost = 0.16046561300754547\n",
      "Batch #:1600, training cost = 0.13567087054252625\n",
      "Batch #:1800, training cost = 0.14514930546283722\n",
      "Batch #:1941, training cost = 0.1741296947002411\n",
      "\n",
      "******************\n",
      " Epoch =  1 \n",
      "\n",
      "Batch #:0, training cost = 0.15968124568462372\n",
      "Batch #:200, training cost = 0.20019419491291046\n",
      "Batch #:400, training cost = 0.1418304443359375\n",
      "Batch #:600, training cost = 0.14474396407604218\n",
      "Batch #:800, training cost = 0.13803234696388245\n",
      "Batch #:1000, training cost = 0.1568545401096344\n",
      "Batch #:1200, training cost = 0.15620985627174377\n",
      "Batch #:1400, training cost = 0.14903922379016876\n",
      "Batch #:1600, training cost = 0.13018903136253357\n",
      "Batch #:1800, training cost = 0.13582995533943176\n",
      "Batch #:1941, training cost = 0.16784177720546722\n",
      "\n",
      "******************\n",
      " Epoch =  2 \n",
      "\n",
      "Batch #:0, training cost = 0.15647466480731964\n",
      "Batch #:200, training cost = 0.195577472448349\n",
      "Batch #:400, training cost = 0.13473927974700928\n",
      "Batch #:600, training cost = 0.14118355512619019\n",
      "Batch #:800, training cost = 0.13110192120075226\n",
      "Batch #:1000, training cost = 0.14871610701084137\n",
      "Batch #:1200, training cost = 0.14929594099521637\n",
      "Batch #:1400, training cost = 0.14259174466133118\n",
      "Batch #:1600, training cost = 0.1255721002817154\n",
      "Batch #:1800, training cost = 0.13328571617603302\n",
      "Batch #:1941, training cost = 0.1614227294921875\n",
      "\n",
      "******************\n",
      " Epoch =  3 \n",
      "\n",
      "Batch #:0, training cost = 0.15176759660243988\n",
      "Batch #:200, training cost = 0.19107331335544586\n",
      "Batch #:400, training cost = 0.13062722980976105\n",
      "Batch #:600, training cost = 0.13673898577690125\n",
      "Batch #:800, training cost = 0.12471224367618561\n",
      "Batch #:1000, training cost = 0.14337512850761414\n",
      "Batch #:1200, training cost = 0.14206795394420624\n",
      "Batch #:1400, training cost = 0.13537439703941345\n",
      "Batch #:1600, training cost = 0.12120179086923599\n",
      "Batch #:1800, training cost = 0.13066332042217255\n",
      "Batch #:1941, training cost = 0.15811645984649658\n",
      "\n",
      "******************\n",
      " Epoch =  4 \n",
      "\n",
      "Batch #:0, training cost = 0.14703777432441711\n",
      "Batch #:200, training cost = 0.18574228882789612\n",
      "Batch #:400, training cost = 0.1262464076280594\n",
      "Batch #:600, training cost = 0.1336500644683838\n",
      "Batch #:800, training cost = 0.11937029659748077\n",
      "Batch #:1000, training cost = 0.13918642699718475\n",
      "Batch #:1200, training cost = 0.1360923796892166\n",
      "Batch #:1400, training cost = 0.1313330978155136\n",
      "Batch #:1600, training cost = 0.11727824062108994\n",
      "Batch #:1800, training cost = 0.12806572020053864\n",
      "Batch #:1941, training cost = 0.15445110201835632\n",
      "\n",
      "******************\n",
      " Epoch =  5 \n",
      "\n",
      "Batch #:0, training cost = 0.14314790070056915\n",
      "Batch #:200, training cost = 0.1834794133901596\n",
      "Batch #:400, training cost = 0.12290750443935394\n",
      "Batch #:600, training cost = 0.1290588229894638\n",
      "Batch #:800, training cost = 0.11390019953250885\n",
      "Batch #:1000, training cost = 0.13354167342185974\n",
      "Batch #:1200, training cost = 0.13039769232273102\n",
      "Batch #:1400, training cost = 0.12522375583648682\n",
      "Batch #:1600, training cost = 0.11325390636920929\n",
      "Batch #:1800, training cost = 0.12478173524141312\n",
      "Batch #:1941, training cost = 0.1507691591978073\n",
      "\n",
      "******************\n",
      " Epoch =  6 \n",
      "\n",
      "Batch #:0, training cost = 0.1399967521429062\n",
      "Batch #:200, training cost = 0.17724056541919708\n",
      "Batch #:400, training cost = 0.11943475157022476\n",
      "Batch #:600, training cost = 0.12447340041399002\n",
      "Batch #:800, training cost = 0.10858919471502304\n",
      "Batch #:1000, training cost = 0.12898099422454834\n",
      "Batch #:1200, training cost = 0.12417370826005936\n",
      "Batch #:1400, training cost = 0.11958611756563187\n",
      "Batch #:1600, training cost = 0.10819513350725174\n",
      "Batch #:1800, training cost = 0.1196167841553688\n",
      "Batch #:1941, training cost = 0.14578962326049805\n",
      "\n",
      "******************\n",
      " Epoch =  7 \n",
      "\n",
      "Batch #:0, training cost = 0.13601212203502655\n",
      "Batch #:200, training cost = 0.16936799883842468\n",
      "Batch #:400, training cost = 0.1167156919836998\n",
      "Batch #:600, training cost = 0.12067615240812302\n",
      "Batch #:800, training cost = 0.10398697853088379\n",
      "Batch #:1000, training cost = 0.12378821521997452\n",
      "Batch #:1200, training cost = 0.11602834612131119\n",
      "Batch #:1400, training cost = 0.11227618157863617\n",
      "Batch #:1600, training cost = 0.10370278358459473\n",
      "Batch #:1800, training cost = 0.11392601579427719\n",
      "Batch #:1941, training cost = 0.13816054165363312\n",
      "\n",
      "******************\n",
      " Epoch =  8 \n",
      "\n",
      "Batch #:0, training cost = 0.1314035803079605\n",
      "Batch #:200, training cost = 0.16032220423221588\n",
      "Batch #:400, training cost = 0.11365924775600433\n",
      "Batch #:600, training cost = 0.11584515124559402\n",
      "Batch #:800, training cost = 0.09783222526311874\n",
      "Batch #:1000, training cost = 0.11915004253387451\n",
      "Batch #:1200, training cost = 0.106105275452137\n",
      "Batch #:1400, training cost = 0.10511128604412079\n",
      "Batch #:1600, training cost = 0.09831641614437103\n",
      "Batch #:1800, training cost = 0.10755879431962967\n",
      "Batch #:1941, training cost = 0.131256565451622\n",
      "\n",
      "******************\n",
      " Epoch =  9 \n",
      "\n",
      "Batch #:0, training cost = 0.12722007930278778\n",
      "Batch #:200, training cost = 0.15014851093292236\n",
      "Batch #:400, training cost = 0.11053572595119476\n",
      "Batch #:600, training cost = 0.10999266803264618\n",
      "Batch #:800, training cost = 0.09069778770208359\n",
      "Batch #:1000, training cost = 0.1129559651017189\n",
      "Batch #:1200, training cost = 0.09737837314605713\n",
      "Batch #:1400, training cost = 0.09759378433227539\n",
      "Batch #:1600, training cost = 0.09306590259075165\n",
      "Batch #:1800, training cost = 0.10165313631296158\n",
      "Batch #:1941, training cost = 0.12400443106889725\n",
      "\n",
      "******************\n",
      " Epoch =  10 \n",
      "\n",
      "Batch #:0, training cost = 0.1224062591791153\n",
      "Batch #:200, training cost = 0.1412479728460312\n",
      "Batch #:400, training cost = 0.1051386222243309\n",
      "Batch #:600, training cost = 0.10362138599157333\n",
      "Batch #:800, training cost = 0.08535405248403549\n",
      "Batch #:1000, training cost = 0.10934392362833023\n",
      "Batch #:1200, training cost = 0.08743207156658173\n",
      "Batch #:1400, training cost = 0.09086336940526962\n",
      "Batch #:1600, training cost = 0.08957689255475998\n",
      "Batch #:1800, training cost = 0.0957111045718193\n",
      "Batch #:1941, training cost = 0.11344881355762482\n",
      "\n",
      "******************\n",
      " Epoch =  11 \n",
      "\n",
      "Batch #:0, training cost = 0.11829202622175217\n",
      "Batch #:200, training cost = 0.13136334717273712\n",
      "Batch #:400, training cost = 0.10010982304811478\n",
      "Batch #:600, training cost = 0.095326267182827\n",
      "Batch #:800, training cost = 0.07931913435459137\n",
      "Batch #:1000, training cost = 0.10288337618112564\n",
      "Batch #:1200, training cost = 0.07975154370069504\n",
      "Batch #:1400, training cost = 0.08523084223270416\n",
      "Batch #:1600, training cost = 0.08317656815052032\n",
      "Batch #:1800, training cost = 0.08887482434511185\n",
      "Batch #:1941, training cost = 0.10713519155979156\n",
      "\n",
      "******************\n",
      " Epoch =  12 \n",
      "\n",
      "Batch #:0, training cost = 0.11264761537313461\n",
      "Batch #:200, training cost = 0.12051542103290558\n",
      "Batch #:400, training cost = 0.09402881562709808\n",
      "Batch #:600, training cost = 0.08989305794239044\n",
      "Batch #:800, training cost = 0.07313340157270432\n",
      "Batch #:1000, training cost = 0.0949786975979805\n",
      "Batch #:1200, training cost = 0.07294583320617676\n",
      "Batch #:1400, training cost = 0.07716512680053711\n",
      "Batch #:1600, training cost = 0.07845193892717361\n",
      "Batch #:1800, training cost = 0.07951384037733078\n",
      "Batch #:1941, training cost = 0.09915038198232651\n",
      "\n",
      "******************\n",
      " Epoch =  13 \n",
      "\n",
      "Batch #:0, training cost = 0.10545537620782852\n",
      "Batch #:200, training cost = 0.10762885957956314\n",
      "Batch #:400, training cost = 0.08855652809143066\n",
      "Batch #:600, training cost = 0.08145143836736679\n",
      "Batch #:800, training cost = 0.06513016670942307\n",
      "Batch #:1000, training cost = 0.08856648951768875\n",
      "Batch #:1200, training cost = 0.06474718451499939\n",
      "Batch #:1400, training cost = 0.0684540793299675\n",
      "Batch #:1600, training cost = 0.07512199878692627\n",
      "Batch #:1800, training cost = 0.0719236209988594\n",
      "Batch #:1941, training cost = 0.0912695899605751\n",
      "\n",
      "******************\n",
      " Epoch =  14 \n",
      "\n",
      "Batch #:0, training cost = 0.09857314825057983\n",
      "Batch #:200, training cost = 0.09583104401826859\n",
      "Batch #:400, training cost = 0.0840737372636795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #:600, training cost = 0.07424049079418182\n",
      "Batch #:800, training cost = 0.058421168476343155\n",
      "Batch #:1000, training cost = 0.08064208179712296\n",
      "Batch #:1200, training cost = 0.05877092108130455\n",
      "Batch #:1400, training cost = 0.06003878638148308\n",
      "Batch #:1600, training cost = 0.07058907300233841\n",
      "Batch #:1800, training cost = 0.06354384869337082\n",
      "Batch #:1941, training cost = 0.08332794904708862\n",
      "\n",
      "******************\n",
      " Epoch =  15 \n",
      "\n",
      "Batch #:0, training cost = 0.09054569900035858\n",
      "Batch #:200, training cost = 0.08722466975450516\n",
      "Batch #:400, training cost = 0.07733004540205002\n",
      "Batch #:600, training cost = 0.06739646196365356\n",
      "Batch #:800, training cost = 0.05063038691878319\n",
      "Batch #:1000, training cost = 0.0709855929017067\n",
      "Batch #:1200, training cost = 0.0517430379986763\n",
      "Batch #:1400, training cost = 0.053722016513347626\n",
      "Batch #:1600, training cost = 0.06632296741008759\n",
      "Batch #:1800, training cost = 0.056813646107912064\n",
      "Batch #:1941, training cost = 0.07744758576154709\n",
      "\n",
      "******************\n",
      " Epoch =  16 \n",
      "\n",
      "Batch #:0, training cost = 0.08324645459651947\n",
      "Batch #:200, training cost = 0.07617272436618805\n",
      "Batch #:400, training cost = 0.07233810424804688\n",
      "Batch #:600, training cost = 0.0625731498003006\n",
      "Batch #:800, training cost = 0.04321027547121048\n",
      "Batch #:1000, training cost = 0.06318766623735428\n",
      "Batch #:1200, training cost = 0.04590758681297302\n",
      "Batch #:1400, training cost = 0.04716257005929947\n",
      "Batch #:1600, training cost = 0.060580573976039886\n",
      "Batch #:1800, training cost = 0.047373831272125244\n",
      "Batch #:1941, training cost = 0.06605641543865204\n",
      "\n",
      "******************\n",
      " Epoch =  17 \n",
      "\n",
      "Batch #:0, training cost = 0.07608696073293686\n",
      "Batch #:200, training cost = 0.06710582226514816\n",
      "Batch #:400, training cost = 0.06894295662641525\n",
      "Batch #:600, training cost = 0.05740951746702194\n",
      "Batch #:800, training cost = 0.03855972737073898\n",
      "Batch #:1000, training cost = 0.056758761405944824\n",
      "Batch #:1200, training cost = 0.04024355486035347\n",
      "Batch #:1400, training cost = 0.03825126960873604\n",
      "Batch #:1600, training cost = 0.055899642407894135\n",
      "Batch #:1800, training cost = 0.04099816456437111\n",
      "Batch #:1941, training cost = 0.056317608803510666\n",
      "\n",
      "******************\n",
      " Epoch =  18 \n",
      "\n",
      "Batch #:0, training cost = 0.07152064889669418\n",
      "Batch #:200, training cost = 0.05806177482008934\n",
      "Batch #:400, training cost = 0.05944163724780083\n",
      "Batch #:600, training cost = 0.05410679802298546\n",
      "Batch #:800, training cost = 0.03373628482222557\n",
      "Batch #:1000, training cost = 0.04840274900197983\n",
      "Batch #:1200, training cost = 0.03624511510133743\n",
      "Batch #:1400, training cost = 0.031746480613946915\n",
      "Batch #:1600, training cost = 0.05128422752022743\n",
      "Batch #:1800, training cost = 0.03687271848320961\n",
      "Batch #:1941, training cost = 0.04998866468667984\n",
      "\n",
      "******************\n",
      " Epoch =  19 \n",
      "\n",
      "Batch #:0, training cost = 0.06776196509599686\n",
      "Batch #:200, training cost = 0.049783386290073395\n",
      "Batch #:400, training cost = 0.049640052020549774\n",
      "Batch #:600, training cost = 0.04923076555132866\n",
      "Batch #:800, training cost = 0.02859668992459774\n",
      "Batch #:1000, training cost = 0.04104860872030258\n",
      "Batch #:1200, training cost = 0.030573159456253052\n",
      "Batch #:1400, training cost = 0.027531394734978676\n",
      "Batch #:1600, training cost = 0.047758933156728745\n",
      "Batch #:1800, training cost = 0.032867301255464554\n",
      "Batch #:1941, training cost = 0.045526836067438126\n",
      "\n",
      "******************\n",
      " Epoch =  20 \n",
      "\n",
      "Batch #:0, training cost = 0.06562972813844681\n",
      "Batch #:200, training cost = 0.04181768372654915\n",
      "Batch #:400, training cost = 0.041325341910123825\n",
      "Batch #:600, training cost = 0.0421791635453701\n",
      "Batch #:800, training cost = 0.025888046249747276\n",
      "Batch #:1000, training cost = 0.033222585916519165\n",
      "Batch #:1200, training cost = 0.02566596306860447\n",
      "Batch #:1400, training cost = 0.024005139246582985\n",
      "Batch #:1600, training cost = 0.042829133570194244\n",
      "Batch #:1800, training cost = 0.027759011834859848\n",
      "Batch #:1941, training cost = 0.03819045424461365\n",
      "\n",
      "******************\n",
      " Epoch =  21 \n",
      "\n",
      "Batch #:0, training cost = 0.05460270121693611\n",
      "Batch #:200, training cost = 0.039487916976213455\n",
      "Batch #:400, training cost = 0.03506169095635414\n",
      "Batch #:600, training cost = 0.03613179922103882\n",
      "Batch #:800, training cost = 0.020776012912392616\n",
      "Batch #:1000, training cost = 0.028704728931188583\n",
      "Batch #:1200, training cost = 0.02152775600552559\n",
      "Batch #:1400, training cost = 0.022754322737455368\n",
      "Batch #:1600, training cost = 0.04435458779335022\n",
      "Batch #:1800, training cost = 0.02621466852724552\n",
      "Batch #:1941, training cost = 0.04149269685149193\n",
      "\n",
      "******************\n",
      " Epoch =  22 \n",
      "\n",
      "Batch #:0, training cost = 0.04915856942534447\n",
      "Batch #:200, training cost = 0.03634139150381088\n",
      "Batch #:400, training cost = 0.03428492695093155\n",
      "Batch #:600, training cost = 0.03609304875135422\n",
      "Batch #:800, training cost = 0.02090802788734436\n",
      "Batch #:1000, training cost = 0.029843715950846672\n",
      "Batch #:1200, training cost = 0.02080691047012806\n",
      "Batch #:1400, training cost = 0.020636649802327156\n",
      "Batch #:1600, training cost = 0.04203309491276741\n",
      "Batch #:1800, training cost = 0.021732578054070473\n",
      "Batch #:1941, training cost = 0.0528487004339695\n",
      "\n",
      "******************\n",
      " Epoch =  23 \n",
      "\n",
      "Batch #:0, training cost = 0.05435776337981224\n",
      "Batch #:200, training cost = 0.035724494606256485\n",
      "Batch #:400, training cost = 0.030658096075057983\n",
      "Batch #:600, training cost = 0.04637470096349716\n",
      "Batch #:800, training cost = 0.03844688460230827\n",
      "Batch #:1000, training cost = 0.05763854458928108\n",
      "Batch #:1200, training cost = 0.03145866468548775\n",
      "Batch #:1400, training cost = 0.04923805966973305\n",
      "Batch #:1600, training cost = 0.04801063984632492\n",
      "Batch #:1800, training cost = 0.027833925560116768\n",
      "Batch #:1941, training cost = 0.03402755782008171\n",
      "\n",
      "******************\n",
      " Epoch =  24 \n",
      "\n",
      "Batch #:0, training cost = 0.06124496087431908\n",
      "Batch #:200, training cost = 0.058546848595142365\n",
      "Batch #:400, training cost = 0.029529064893722534\n",
      "Batch #:600, training cost = 0.056237008422613144\n",
      "Batch #:800, training cost = 0.029160553589463234\n",
      "Batch #:1000, training cost = 0.02468564175069332\n",
      "Batch #:1200, training cost = 0.031083736568689346\n",
      "Batch #:1400, training cost = 0.028771044686436653\n",
      "Batch #:1600, training cost = 0.04038413614034653\n",
      "Batch #:1800, training cost = 0.021260647103190422\n",
      "Batch #:1941, training cost = 0.026631522923707962\n",
      "\n",
      "******************\n",
      " Epoch =  25 \n",
      "\n",
      "Batch #:0, training cost = 0.046673793345689774\n",
      "Batch #:200, training cost = 0.044295065104961395\n",
      "Batch #:400, training cost = 0.030215846374630928\n",
      "Batch #:600, training cost = 0.034165557473897934\n",
      "Batch #:800, training cost = 0.024908829480409622\n",
      "Batch #:1000, training cost = 0.020953627303242683\n",
      "Batch #:1200, training cost = 0.014033800922334194\n",
      "Batch #:1400, training cost = 0.020353704690933228\n",
      "Batch #:1600, training cost = 0.03143632039427757\n",
      "Batch #:1800, training cost = 0.01959468238055706\n",
      "Batch #:1941, training cost = 0.022299477830529213\n",
      "\n",
      "******************\n",
      " Epoch =  26 \n",
      "\n",
      "Batch #:0, training cost = 0.041975390166044235\n",
      "Batch #:200, training cost = 0.04531233385205269\n",
      "Batch #:400, training cost = 0.023277031257748604\n",
      "Batch #:600, training cost = 0.026897771283984184\n",
      "Batch #:800, training cost = 0.021919013932347298\n",
      "Batch #:1000, training cost = 0.024506347253918648\n",
      "Batch #:1200, training cost = 0.011427116580307484\n",
      "Batch #:1400, training cost = 0.02357601746916771\n",
      "Batch #:1600, training cost = 0.032775674015283585\n",
      "Batch #:1800, training cost = 0.014942144975066185\n",
      "Batch #:1941, training cost = 0.024271896108984947\n",
      "\n",
      "******************\n",
      " Epoch =  27 \n",
      "\n",
      "Batch #:0, training cost = 0.032515984028577805\n",
      "Batch #:200, training cost = 0.03303973749279976\n",
      "Batch #:400, training cost = 0.018051136285066605\n",
      "Batch #:600, training cost = 0.03150148317217827\n",
      "Batch #:800, training cost = 0.02167944610118866\n",
      "Batch #:1000, training cost = 0.025947127491235733\n",
      "Batch #:1200, training cost = 0.012498968280851841\n",
      "Batch #:1400, training cost = 0.028409961611032486\n",
      "Batch #:1600, training cost = 0.02719346061348915\n",
      "Batch #:1800, training cost = 0.015726426616311073\n",
      "Batch #:1941, training cost = 0.030910756438970566\n",
      "\n",
      "******************\n",
      " Epoch =  28 \n",
      "\n",
      "Batch #:0, training cost = 0.027073444798588753\n",
      "Batch #:200, training cost = 0.02749726176261902\n",
      "Batch #:400, training cost = 0.02737927809357643\n",
      "Batch #:600, training cost = 0.032137997448444366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #:800, training cost = 0.022969992831349373\n",
      "Batch #:1000, training cost = 0.017362354323267937\n",
      "Batch #:1200, training cost = 0.020144183188676834\n",
      "Batch #:1400, training cost = 0.03388484567403793\n",
      "Batch #:1600, training cost = 0.025601718574762344\n",
      "Batch #:1800, training cost = 0.015918666496872902\n",
      "Batch #:1941, training cost = 0.02994537726044655\n",
      "\n",
      "******************\n",
      " Epoch =  29 \n",
      "\n",
      "Batch #:0, training cost = 0.03573298454284668\n",
      "Batch #:200, training cost = 0.01875513233244419\n",
      "Batch #:400, training cost = 0.0293464045971632\n",
      "Batch #:600, training cost = 0.028222503140568733\n",
      "Batch #:800, training cost = 0.016333293169736862\n",
      "Batch #:1000, training cost = 0.014857837930321693\n",
      "Batch #:1200, training cost = 0.013233725912868977\n",
      "Batch #:1400, training cost = 0.027426959946751595\n",
      "Batch #:1600, training cost = 0.027665963396430016\n",
      "Batch #:1800, training cost = 0.01871781051158905\n",
      "Batch #:1941, training cost = 0.0231665950268507\n",
      "\n",
      "******************\n",
      " Epoch =  30 \n",
      "\n",
      "Batch #:0, training cost = 0.02857658453285694\n",
      "Batch #:200, training cost = 0.022913707420229912\n",
      "Batch #:400, training cost = 0.028728783130645752\n",
      "Batch #:600, training cost = 0.03465127572417259\n",
      "Batch #:800, training cost = 0.011554260738193989\n",
      "Batch #:1000, training cost = 0.014373228885233402\n",
      "Batch #:1200, training cost = 0.011747538112103939\n",
      "Batch #:1400, training cost = 0.017583969980478287\n",
      "Batch #:1600, training cost = 0.027578091248869896\n",
      "Batch #:1800, training cost = 0.016846556216478348\n",
      "Batch #:1941, training cost = 0.02077593468129635\n",
      "\n",
      "******************\n",
      " Epoch =  31 \n",
      "\n",
      "Batch #:0, training cost = 0.03835633769631386\n",
      "Batch #:200, training cost = 0.02359904907643795\n",
      "Batch #:400, training cost = 0.021645445376634598\n",
      "Batch #:600, training cost = 0.027994409203529358\n",
      "Batch #:800, training cost = 0.008828377351164818\n",
      "Batch #:1000, training cost = 0.021365946158766747\n",
      "Batch #:1200, training cost = 0.014541761949658394\n",
      "Batch #:1400, training cost = 0.017360001802444458\n",
      "Batch #:1600, training cost = 0.019739540293812752\n",
      "Batch #:1800, training cost = 0.018222445622086525\n",
      "Batch #:1941, training cost = 0.027557626366615295\n",
      "\n",
      "******************\n",
      " Epoch =  32 \n",
      "\n",
      "Batch #:0, training cost = 0.03818276524543762\n",
      "Batch #:200, training cost = 0.023649094626307487\n",
      "Batch #:400, training cost = 0.025703715160489082\n",
      "Batch #:600, training cost = 0.026598790660500526\n",
      "Batch #:800, training cost = 0.009751662611961365\n",
      "Batch #:1000, training cost = 0.014528066851198673\n",
      "Batch #:1200, training cost = 0.026220697909593582\n",
      "Batch #:1400, training cost = 0.017138920724391937\n",
      "Batch #:1600, training cost = 0.0205841101706028\n",
      "Batch #:1800, training cost = 0.014277035370469093\n",
      "Batch #:1941, training cost = 0.021891970187425613\n",
      "\n",
      "******************\n",
      " Epoch =  33 \n",
      "\n",
      "Batch #:0, training cost = 0.0314997173845768\n",
      "Batch #:200, training cost = 0.02270091138780117\n",
      "Batch #:400, training cost = 0.022511418908834457\n",
      "Batch #:600, training cost = 0.012982659973204136\n",
      "Batch #:800, training cost = 0.01190713606774807\n",
      "Batch #:1000, training cost = 0.01896969974040985\n",
      "Batch #:1200, training cost = 0.023497706279158592\n",
      "Batch #:1400, training cost = 0.011800927110016346\n",
      "Batch #:1600, training cost = 0.01671205647289753\n",
      "Batch #:1800, training cost = 0.009296977892518044\n",
      "Batch #:1941, training cost = 0.01535589899867773\n",
      "\n",
      "******************\n",
      " Epoch =  34 \n",
      "\n",
      "Batch #:0, training cost = 0.030063772574067116\n",
      "Batch #:200, training cost = 0.01931649260222912\n",
      "Batch #:400, training cost = 0.027420666068792343\n",
      "Batch #:600, training cost = 0.010483779013156891\n",
      "Batch #:800, training cost = 0.012211381457746029\n",
      "Batch #:1000, training cost = 0.02006533369421959\n",
      "Batch #:1200, training cost = 0.021718868985772133\n",
      "Batch #:1400, training cost = 0.013731082901358604\n",
      "Batch #:1600, training cost = 0.014425116591155529\n",
      "Batch #:1800, training cost = 0.02102324180305004\n",
      "Batch #:1941, training cost = 0.010049387812614441\n",
      "\n",
      "******************\n",
      " Epoch =  35 \n",
      "\n",
      "Batch #:0, training cost = 0.017948776483535767\n",
      "Batch #:200, training cost = 0.018413769081234932\n",
      "Batch #:400, training cost = 0.019539447501301765\n",
      "Batch #:600, training cost = 0.017615245655179024\n",
      "Batch #:800, training cost = 0.015938224270939827\n",
      "Batch #:1000, training cost = 0.019392158836126328\n",
      "Batch #:1200, training cost = 0.01387207955121994\n",
      "Batch #:1400, training cost = 0.008457915857434273\n",
      "Batch #:1600, training cost = 0.014226479455828667\n",
      "Batch #:1800, training cost = 0.013164126314222813\n",
      "Batch #:1941, training cost = 0.015481161884963512\n",
      "\n",
      "******************\n",
      " Epoch =  36 \n",
      "\n",
      "Batch #:0, training cost = 0.021867167204618454\n",
      "Batch #:200, training cost = 0.00844560842961073\n",
      "Batch #:400, training cost = 0.01619771309196949\n",
      "Batch #:600, training cost = 0.012389174662530422\n",
      "Batch #:800, training cost = 0.00946556031703949\n",
      "Batch #:1000, training cost = 0.010434979572892189\n",
      "Batch #:1200, training cost = 0.016415821388363838\n",
      "Batch #:1400, training cost = 0.007983851246535778\n",
      "Batch #:1600, training cost = 0.012350217439234257\n",
      "Batch #:1800, training cost = 0.014902018010616302\n",
      "Batch #:1941, training cost = 0.011724627576768398\n",
      "\n",
      "******************\n",
      " Epoch =  37 \n",
      "\n",
      "Batch #:0, training cost = 0.014398792758584023\n",
      "Batch #:200, training cost = 0.009108769707381725\n",
      "Batch #:400, training cost = 0.011889970861375332\n",
      "Batch #:600, training cost = 0.01393950916826725\n",
      "Batch #:800, training cost = 0.009139209985733032\n",
      "Batch #:1000, training cost = 0.015963071957230568\n",
      "Batch #:1200, training cost = 0.022027021273970604\n",
      "Batch #:1400, training cost = 0.007337127812206745\n",
      "Batch #:1600, training cost = 0.013843460939824581\n",
      "Batch #:1800, training cost = 0.013955017551779747\n",
      "Batch #:1941, training cost = 0.015081296674907207\n",
      "\n",
      "******************\n",
      " Epoch =  38 \n",
      "\n",
      "Batch #:0, training cost = 0.016397375613451004\n",
      "Batch #:200, training cost = 0.012665865011513233\n",
      "Batch #:400, training cost = 0.018045200034976006\n",
      "Batch #:600, training cost = 0.01285215187817812\n",
      "Batch #:800, training cost = 0.021702472120523453\n",
      "Batch #:1000, training cost = 0.028705041855573654\n",
      "Batch #:1200, training cost = 0.011399621143937111\n",
      "Batch #:1400, training cost = 0.01326318271458149\n",
      "Batch #:1600, training cost = 0.028178904205560684\n",
      "Batch #:1800, training cost = 0.0077033438719809055\n",
      "Batch #:1941, training cost = 0.008710062131285667\n",
      "\n",
      "******************\n",
      " Epoch =  39 \n",
      "\n",
      "Batch #:0, training cost = 0.015737975016236305\n",
      "Batch #:200, training cost = 0.010360590182244778\n",
      "Batch #:400, training cost = 0.015441256575286388\n",
      "Batch #:600, training cost = 0.015155209228396416\n",
      "Batch #:800, training cost = 0.006731683854013681\n",
      "Batch #:1000, training cost = 0.010536333546042442\n",
      "Batch #:1200, training cost = 0.009546601213514805\n",
      "Batch #:1400, training cost = 0.01360763143748045\n",
      "Batch #:1600, training cost = 0.01021274458616972\n",
      "Batch #:1800, training cost = 0.006245502736419439\n",
      "Batch #:1941, training cost = 0.014970910735428333\n",
      "\n",
      "******************\n",
      " Epoch =  40 \n",
      "\n",
      "Batch #:0, training cost = 0.01312921941280365\n",
      "Batch #:200, training cost = 0.01105282548815012\n",
      "Batch #:400, training cost = 0.01801641285419464\n",
      "Batch #:600, training cost = 0.012205512262880802\n",
      "Batch #:800, training cost = 0.0117494473233819\n",
      "Batch #:1000, training cost = 0.010208606719970703\n",
      "Batch #:1200, training cost = 0.0074872239492833614\n",
      "Batch #:1400, training cost = 0.008767493069171906\n",
      "Batch #:1600, training cost = 0.007392742205411196\n",
      "Batch #:1800, training cost = 0.015744248405098915\n",
      "Batch #:1941, training cost = 0.011346196755766869\n",
      "\n",
      "******************\n",
      " Epoch =  41 \n",
      "\n",
      "Batch #:0, training cost = 0.008062049746513367\n",
      "Batch #:200, training cost = 0.015082855708897114\n",
      "Batch #:400, training cost = 0.012861812487244606\n",
      "Batch #:600, training cost = 0.0104371951892972\n",
      "Batch #:800, training cost = 0.009563716128468513\n",
      "Batch #:1000, training cost = 0.02313201315701008\n",
      "Batch #:1200, training cost = 0.008941927924752235\n",
      "Batch #:1400, training cost = 0.00974145345389843\n",
      "Batch #:1600, training cost = 0.007264637853950262\n",
      "Batch #:1800, training cost = 0.008350763469934464\n",
      "Batch #:1941, training cost = 0.020211363211274147\n",
      "\n",
      "******************\n",
      " Epoch =  42 \n",
      "\n",
      "Batch #:0, training cost = 0.014456859789788723\n",
      "Batch #:200, training cost = 0.020337367430329323\n",
      "Batch #:400, training cost = 0.010730155743658543\n",
      "Batch #:600, training cost = 0.008927744813263416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #:800, training cost = 0.012008381076157093\n",
      "Batch #:1000, training cost = 0.00845798384398222\n",
      "Batch #:1200, training cost = 0.005136299412697554\n",
      "Batch #:1400, training cost = 0.012943061999976635\n",
      "Batch #:1600, training cost = 0.01333568524569273\n",
      "Batch #:1800, training cost = 0.012880234979093075\n",
      "Batch #:1941, training cost = 0.004938341677188873\n",
      "\n",
      "******************\n",
      " Epoch =  43 \n",
      "\n",
      "Batch #:0, training cost = 0.009479327127337456\n",
      "Batch #:200, training cost = 0.024244891479611397\n",
      "Batch #:400, training cost = 0.007937918417155743\n",
      "Batch #:600, training cost = 0.01886686682701111\n",
      "Batch #:800, training cost = 0.010045918636023998\n",
      "Batch #:1000, training cost = 0.010264582931995392\n",
      "Batch #:1200, training cost = 0.005914271809160709\n",
      "Batch #:1400, training cost = 0.012803097255527973\n",
      "Batch #:1600, training cost = 0.007644610945135355\n",
      "Batch #:1800, training cost = 0.020695943385362625\n",
      "Batch #:1941, training cost = 0.006615187041461468\n",
      "\n",
      "******************\n",
      " Epoch =  44 \n",
      "\n",
      "Batch #:0, training cost = 0.021755483001470566\n",
      "Batch #:200, training cost = 0.007102443836629391\n",
      "Batch #:400, training cost = 0.004462722223252058\n",
      "Batch #:600, training cost = 0.01367672998458147\n",
      "Batch #:800, training cost = 0.009861315600574017\n",
      "Batch #:1000, training cost = 0.006553721614181995\n",
      "Batch #:1200, training cost = 0.0061503141187131405\n",
      "Batch #:1400, training cost = 0.01011247094720602\n",
      "Batch #:1600, training cost = 0.0077804881148040295\n",
      "Batch #:1800, training cost = 0.005173245910555124\n",
      "Batch #:1941, training cost = 0.006106889806687832\n",
      "\n",
      "******************\n",
      " Epoch =  45 \n",
      "\n",
      "Batch #:0, training cost = 0.009339967742562294\n",
      "Batch #:200, training cost = 0.011891841888427734\n",
      "Batch #:400, training cost = 0.00884923804551363\n",
      "Batch #:600, training cost = 0.006283922586590052\n",
      "Batch #:800, training cost = 0.005351766478270292\n",
      "Batch #:1000, training cost = 0.012047919444739819\n",
      "Batch #:1200, training cost = 0.016268614679574966\n",
      "Batch #:1400, training cost = 0.019587533548474312\n",
      "Batch #:1600, training cost = 0.008565856143832207\n",
      "Batch #:1800, training cost = 0.0071783591993153095\n",
      "Batch #:1941, training cost = 0.010575278662145138\n",
      "\n",
      "******************\n",
      " Epoch =  46 \n",
      "\n",
      "Batch #:0, training cost = 0.008445519022643566\n",
      "Batch #:200, training cost = 0.0059988959692418575\n",
      "Batch #:400, training cost = 0.004143431317061186\n",
      "Batch #:600, training cost = 0.01464189775288105\n",
      "Batch #:800, training cost = 0.008180847391486168\n",
      "Batch #:1000, training cost = 0.004225596319884062\n",
      "Batch #:1200, training cost = 0.011787270195782185\n",
      "Batch #:1400, training cost = 0.02236899547278881\n",
      "Batch #:1600, training cost = 0.006604435853660107\n",
      "Batch #:1800, training cost = 0.009613491594791412\n",
      "Batch #:1941, training cost = 0.004662787076085806\n",
      "\n",
      "******************\n",
      " Epoch =  47 \n",
      "\n",
      "Batch #:0, training cost = 0.010267907753586769\n",
      "Batch #:200, training cost = 0.004423916339874268\n",
      "Batch #:400, training cost = 0.005573124159127474\n",
      "Batch #:600, training cost = 0.011076989583671093\n",
      "Batch #:800, training cost = 0.004750350955873728\n",
      "Batch #:1000, training cost = 0.015059839002788067\n",
      "Batch #:1200, training cost = 0.036126572638750076\n",
      "Batch #:1400, training cost = 0.008317878469824791\n",
      "Batch #:1600, training cost = 0.004994668066501617\n",
      "Batch #:1800, training cost = 0.010679341852664948\n",
      "Batch #:1941, training cost = 0.010021633468568325\n",
      "\n",
      "******************\n",
      " Epoch =  48 \n",
      "\n",
      "Batch #:0, training cost = 0.010684378445148468\n",
      "Batch #:200, training cost = 0.0035058115608990192\n",
      "Batch #:400, training cost = 0.006648600567132235\n",
      "Batch #:600, training cost = 0.007818428799510002\n",
      "Batch #:800, training cost = 0.009320809505879879\n",
      "Batch #:1000, training cost = 0.004956989083439112\n",
      "Batch #:1200, training cost = 0.012679002247750759\n",
      "Batch #:1400, training cost = 0.0059516592882573605\n",
      "Batch #:1600, training cost = 0.007541774772107601\n",
      "Batch #:1800, training cost = 0.006448817905038595\n",
      "Batch #:1941, training cost = 0.00941924937069416\n",
      "\n",
      "******************\n",
      " Epoch =  49 \n",
      "\n",
      "Batch #:0, training cost = 0.008185243234038353\n",
      "Batch #:200, training cost = 0.007489202078431845\n",
      "Batch #:400, training cost = 0.004647917579859495\n",
      "Batch #:600, training cost = 0.011898352764546871\n",
      "Batch #:800, training cost = 0.009703993797302246\n",
      "Batch #:1000, training cost = 0.004625917412340641\n",
      "Batch #:1200, training cost = 0.006719231605529785\n",
      "Batch #:1400, training cost = 0.00335095077753067\n",
      "Batch #:1600, training cost = 0.017345961183309555\n",
      "Batch #:1800, training cost = 0.010297034867107868\n",
      "Batch #:1941, training cost = 0.00670983362942934\n",
      "\n",
      "******************\n",
      " Epoch =  50 \n",
      "\n",
      "Batch #:0, training cost = 0.008172859437763691\n",
      "Batch #:200, training cost = 0.0034358191769570112\n",
      "Batch #:400, training cost = 0.00931111816316843\n",
      "Batch #:600, training cost = 0.011105178855359554\n",
      "Batch #:800, training cost = 0.012108080089092255\n",
      "Batch #:1000, training cost = 0.015813743695616722\n",
      "Batch #:1200, training cost = 0.0032958942465484142\n",
      "Batch #:1400, training cost = 0.004264283459633589\n",
      "Batch #:1600, training cost = 0.008541985414922237\n",
      "Batch #:1800, training cost = 0.01764095202088356\n",
      "Batch #:1941, training cost = 0.005985836032778025\n",
      "\n",
      "******************\n",
      " Epoch =  51 \n",
      "\n",
      "Batch #:0, training cost = 0.00790969468653202\n",
      "Batch #:200, training cost = 0.0048593017272651196\n",
      "Batch #:400, training cost = 0.010049590840935707\n",
      "Batch #:600, training cost = 0.00585284736007452\n",
      "Batch #:800, training cost = 0.008635492995381355\n",
      "Batch #:1000, training cost = 0.0032342385966330767\n",
      "Batch #:1200, training cost = 0.010186152532696724\n",
      "Batch #:1400, training cost = 0.005808185786008835\n",
      "Batch #:1600, training cost = 0.005355874542146921\n",
      "Batch #:1800, training cost = 0.004031782038509846\n",
      "Batch #:1941, training cost = 0.0090035954490304\n",
      "\n",
      "******************\n",
      " Epoch =  52 \n",
      "\n",
      "Batch #:0, training cost = 0.012777743861079216\n",
      "Batch #:200, training cost = 0.00841130968183279\n",
      "Batch #:400, training cost = 0.005645800847560167\n",
      "Batch #:600, training cost = 0.00832163542509079\n",
      "Batch #:800, training cost = 0.008043734356760979\n",
      "Batch #:1000, training cost = 0.005252753384411335\n",
      "Batch #:1200, training cost = 0.003348331432789564\n",
      "Batch #:1400, training cost = 0.0025113809388130903\n",
      "Batch #:1600, training cost = 0.02095271274447441\n",
      "Batch #:1800, training cost = 0.006675207521766424\n",
      "Batch #:1941, training cost = 0.003702800255268812\n",
      "\n",
      "******************\n",
      " Epoch =  53 \n",
      "\n",
      "Batch #:0, training cost = 0.012018730863928795\n",
      "Batch #:200, training cost = 0.007502510212361813\n",
      "Batch #:400, training cost = 0.01706196554005146\n",
      "Batch #:600, training cost = 0.00405906792730093\n",
      "Batch #:800, training cost = 0.010427725501358509\n",
      "Batch #:1000, training cost = 0.0030921429861336946\n",
      "Batch #:1200, training cost = 0.0028068216051906347\n",
      "Batch #:1400, training cost = 0.0023264498449862003\n",
      "Batch #:1600, training cost = 0.004331477917730808\n",
      "Batch #:1800, training cost = 0.002318286569789052\n",
      "Batch #:1941, training cost = 0.005712467711418867\n",
      "\n",
      "******************\n",
      " Epoch =  54 \n",
      "\n",
      "Batch #:0, training cost = 0.008360560052096844\n",
      "Batch #:200, training cost = 0.00404075812548399\n",
      "Batch #:400, training cost = 0.006249965634196997\n",
      "Batch #:600, training cost = 0.005985061172395945\n",
      "Batch #:800, training cost = 0.009936629794538021\n",
      "Batch #:1000, training cost = 0.002399395452812314\n",
      "Batch #:1200, training cost = 0.005447475705295801\n",
      "Batch #:1400, training cost = 0.0025395562406629324\n",
      "Batch #:1600, training cost = 0.011984758079051971\n",
      "Batch #:1800, training cost = 0.007395531516522169\n",
      "Batch #:1941, training cost = 0.0037756471429020166\n",
      "\n",
      "******************\n",
      " Epoch =  55 \n",
      "\n",
      "Batch #:0, training cost = 0.0023159070406109095\n",
      "Batch #:200, training cost = 0.004777479916810989\n",
      "Batch #:400, training cost = 0.0024710013531148434\n",
      "Batch #:600, training cost = 0.006342317443341017\n",
      "Batch #:800, training cost = 0.009174126200377941\n",
      "Batch #:1000, training cost = 0.004019929561764002\n",
      "Batch #:1200, training cost = 0.0032282588072121143\n",
      "Batch #:1400, training cost = 0.007690546568483114\n",
      "Batch #:1600, training cost = 0.02239455282688141\n",
      "Batch #:1800, training cost = 0.010745517909526825\n",
      "Batch #:1941, training cost = 0.0036305109970271587\n",
      "\n",
      "******************\n",
      " Epoch =  56 \n",
      "\n",
      "Batch #:0, training cost = 0.01103578694164753\n",
      "Batch #:200, training cost = 0.002307930728420615\n",
      "Batch #:400, training cost = 0.005537916906177998\n",
      "Batch #:600, training cost = 0.01255799736827612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #:800, training cost = 0.0015476344851776958\n",
      "Batch #:1000, training cost = 0.0031199331860989332\n",
      "Batch #:1200, training cost = 0.0025799700524657965\n",
      "Batch #:1400, training cost = 0.0055852667428553104\n",
      "Batch #:1600, training cost = 0.004503822419792414\n",
      "Batch #:1800, training cost = 0.0030449612531811\n",
      "Batch #:1941, training cost = 0.0018418041290715337\n",
      "\n",
      "******************\n",
      " Epoch =  57 \n",
      "\n",
      "Batch #:0, training cost = 0.006775803864002228\n",
      "Batch #:200, training cost = 0.011236210353672504\n",
      "Batch #:400, training cost = 0.005749449133872986\n",
      "Batch #:600, training cost = 0.004626073408871889\n",
      "Batch #:800, training cost = 0.00679801544174552\n",
      "Batch #:1000, training cost = 0.008415380492806435\n",
      "Batch #:1200, training cost = 0.0028442780021578074\n",
      "Batch #:1400, training cost = 0.006410627625882626\n",
      "Batch #:1600, training cost = 0.004623671527951956\n",
      "Batch #:1800, training cost = 0.0006735222414135933\n",
      "Batch #:1941, training cost = 0.004561820533126593\n",
      "\n",
      "******************\n",
      " Epoch =  58 \n",
      "\n",
      "Batch #:0, training cost = 0.00800730288028717\n",
      "Batch #:200, training cost = 0.0023789182305336\n",
      "Batch #:400, training cost = 0.010354972444474697\n",
      "Batch #:600, training cost = 0.004586667753756046\n",
      "Batch #:800, training cost = 0.007857580669224262\n",
      "Batch #:1000, training cost = 0.020438706502318382\n",
      "Batch #:1200, training cost = 0.0021488515194505453\n",
      "Batch #:1400, training cost = 0.006794128101319075\n",
      "Batch #:1600, training cost = 0.0059363930486142635\n",
      "Batch #:1800, training cost = 0.0024614736903458834\n",
      "Batch #:1941, training cost = 0.008370176889002323\n",
      "\n",
      "******************\n",
      " Epoch =  59 \n",
      "\n",
      "Batch #:0, training cost = 0.010499645955860615\n",
      "Batch #:200, training cost = 0.0048821126110851765\n",
      "Batch #:400, training cost = 0.009248500689864159\n",
      "Batch #:600, training cost = 0.004526934120804071\n",
      "Batch #:800, training cost = 0.015006816945970058\n",
      "Batch #:1000, training cost = 0.013395761139690876\n",
      "Batch #:1200, training cost = 0.003105678129941225\n",
      "Batch #:1400, training cost = 0.0062960414215922356\n",
      "Batch #:1600, training cost = 0.0035289099905639887\n",
      "Batch #:1800, training cost = 0.0015449216589331627\n",
      "Batch #:1941, training cost = 0.01403213944286108\n",
      "\n",
      "******************\n",
      " Epoch =  60 \n",
      "\n",
      "Batch #:0, training cost = 0.009039626456797123\n",
      "Batch #:200, training cost = 0.007511357311159372\n",
      "Batch #:400, training cost = 0.005279248114675283\n",
      "Batch #:600, training cost = 0.004366927780210972\n",
      "Batch #:800, training cost = 0.0034792334772646427\n",
      "Batch #:1000, training cost = 0.0021642919164150953\n",
      "Batch #:1200, training cost = 0.004279055632650852\n",
      "Batch #:1400, training cost = 0.004506593104451895\n",
      "Batch #:1600, training cost = 0.015779897570610046\n",
      "Batch #:1800, training cost = 0.005417641717940569\n",
      "Batch #:1941, training cost = 0.0015053745592013001\n",
      "\n",
      "******************\n",
      " Epoch =  61 \n",
      "\n",
      "Batch #:0, training cost = 0.003248179331421852\n",
      "Batch #:200, training cost = 0.020450307056307793\n",
      "Batch #:400, training cost = 0.004230152349919081\n",
      "Batch #:600, training cost = 0.0016573074972257018\n",
      "Batch #:800, training cost = 0.013053487055003643\n",
      "Batch #:1000, training cost = 0.0018827797612175345\n",
      "Batch #:1200, training cost = 0.0035057461354881525\n",
      "Batch #:1400, training cost = 0.0026457731146365404\n",
      "Batch #:1600, training cost = 0.0011716773733496666\n",
      "Batch #:1800, training cost = 0.0005885600694455206\n",
      "Batch #:1941, training cost = 0.0020995826926082373\n",
      "\n",
      "******************\n",
      " Epoch =  62 \n",
      "\n",
      "Batch #:0, training cost = 0.004433823749423027\n",
      "Batch #:200, training cost = 0.006461349781602621\n",
      "Batch #:400, training cost = 0.002174042398110032\n",
      "Batch #:600, training cost = 0.005579638294875622\n",
      "Batch #:800, training cost = 0.004234743304550648\n",
      "Batch #:1000, training cost = 0.0017408347921445966\n",
      "Batch #:1200, training cost = 0.0013145571574568748\n",
      "Batch #:1400, training cost = 0.0027737373020499945\n",
      "Batch #:1600, training cost = 0.005651192273944616\n",
      "Batch #:1800, training cost = 0.0009226799011230469\n",
      "Batch #:1941, training cost = 0.005191785283386707\n",
      "\n",
      "******************\n",
      " Epoch =  63 \n",
      "\n",
      "Batch #:0, training cost = 0.01500104833394289\n",
      "Batch #:200, training cost = 0.0010508809937164187\n",
      "Batch #:400, training cost = 0.002349483547732234\n",
      "Batch #:600, training cost = 0.0026710883248597383\n",
      "Batch #:800, training cost = 0.00710656400769949\n",
      "Batch #:1000, training cost = 0.004630663897842169\n",
      "Batch #:1200, training cost = 0.006261651869863272\n",
      "Batch #:1400, training cost = 0.0030006058514118195\n",
      "Batch #:1600, training cost = 0.002485159318894148\n",
      "Batch #:1800, training cost = 0.0005470393225550652\n",
      "Batch #:1941, training cost = 0.004806301556527615\n",
      "\n",
      "******************\n",
      " Epoch =  64 \n",
      "\n",
      "Batch #:0, training cost = 0.014378598891198635\n",
      "Batch #:200, training cost = 0.0065335920080542564\n",
      "Batch #:400, training cost = 0.00954331737011671\n",
      "Batch #:600, training cost = 0.004107980988919735\n",
      "Batch #:800, training cost = 0.003985194955021143\n",
      "Batch #:1000, training cost = 0.008932995609939098\n",
      "Batch #:1200, training cost = 0.003148032119497657\n",
      "Batch #:1400, training cost = 0.006870359182357788\n",
      "Batch #:1600, training cost = 0.0025540993083268404\n",
      "Batch #:1800, training cost = 0.003938925918191671\n",
      "Batch #:1941, training cost = 0.004876281134784222\n",
      "\n",
      "******************\n",
      " Epoch =  65 \n",
      "\n",
      "Batch #:0, training cost = 0.002682723570615053\n",
      "Batch #:200, training cost = 0.013370086438953876\n",
      "Batch #:400, training cost = 0.002450077561661601\n",
      "Batch #:600, training cost = 0.004430923145264387\n",
      "Batch #:800, training cost = 0.005063433665782213\n",
      "Batch #:1000, training cost = 0.006928508635610342\n",
      "Batch #:1200, training cost = 0.0023007856216281652\n",
      "Batch #:1400, training cost = 0.003189848270267248\n",
      "Batch #:1600, training cost = 0.00414019450545311\n",
      "Batch #:1800, training cost = 0.01442903932183981\n",
      "Batch #:1941, training cost = 0.005681854207068682\n",
      "\n",
      "******************\n",
      " Epoch =  66 \n",
      "\n",
      "Batch #:0, training cost = 0.005110091529786587\n",
      "Batch #:200, training cost = 0.010627223178744316\n",
      "Batch #:400, training cost = 0.0038509450387209654\n",
      "Batch #:600, training cost = 0.001526537467725575\n",
      "Batch #:800, training cost = 0.002205426571890712\n",
      "Batch #:1000, training cost = 0.0016584886470809579\n",
      "Batch #:1200, training cost = 0.004342080093920231\n",
      "Batch #:1400, training cost = 0.00237411935813725\n",
      "Batch #:1600, training cost = 0.003025457728654146\n",
      "Batch #:1800, training cost = 0.002180050825700164\n",
      "Batch #:1941, training cost = 0.0033328202553093433\n",
      "\n",
      "******************\n",
      " Epoch =  67 \n",
      "\n",
      "Batch #:0, training cost = 0.009272129274904728\n",
      "Batch #:200, training cost = 0.011652437038719654\n",
      "Batch #:400, training cost = 0.0025159637443721294\n",
      "Batch #:600, training cost = 0.004991666879504919\n",
      "Batch #:800, training cost = 0.0030387297738343477\n",
      "Batch #:1000, training cost = 0.0026778369210660458\n",
      "Batch #:1200, training cost = 0.003402651520445943\n",
      "Batch #:1400, training cost = 0.001410963828675449\n",
      "Batch #:1600, training cost = 0.0037842884194105864\n",
      "Batch #:1800, training cost = 0.0009653067099861801\n",
      "Batch #:1941, training cost = 0.010872661136090755\n",
      "\n",
      "******************\n",
      " Epoch =  68 \n",
      "\n",
      "Batch #:0, training cost = 0.003856273600831628\n",
      "Batch #:200, training cost = 0.0026413530576974154\n",
      "Batch #:400, training cost = 0.0019155541667714715\n",
      "Batch #:600, training cost = 0.0027167873922735453\n",
      "Batch #:800, training cost = 0.0018502569291740656\n",
      "Batch #:1000, training cost = 0.0028002350591123104\n",
      "Batch #:1200, training cost = 0.006193709559738636\n",
      "Batch #:1400, training cost = 0.007145038340240717\n",
      "Batch #:1600, training cost = 0.0038181785494089127\n",
      "Batch #:1800, training cost = 0.0006016576662659645\n",
      "Batch #:1941, training cost = 0.0036113939713686705\n",
      "\n",
      "******************\n",
      " Epoch =  69 \n",
      "\n",
      "Batch #:0, training cost = 0.002485203091055155\n",
      "Batch #:200, training cost = 0.004870939999818802\n",
      "Batch #:400, training cost = 0.0008161771111190319\n",
      "Batch #:600, training cost = 0.02451132796704769\n",
      "Batch #:800, training cost = 0.004353582393378019\n",
      "Batch #:1000, training cost = 0.0016185952117666602\n",
      "Batch #:1200, training cost = 0.0022573668975383043\n",
      "Batch #:1400, training cost = 0.013759172521531582\n",
      "Batch #:1600, training cost = 0.009031477384269238\n",
      "Batch #:1800, training cost = 0.001278781914152205\n",
      "Batch #:1941, training cost = 0.002123661106452346\n",
      "\n",
      "******************\n",
      " Epoch =  70 \n",
      "\n",
      "Batch #:0, training cost = 0.00859425961971283\n",
      "Batch #:200, training cost = 0.0025449509266763926\n",
      "Batch #:400, training cost = 0.001070161466486752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #:600, training cost = 0.003584710881114006\n",
      "Batch #:800, training cost = 0.0010817412985488772\n",
      "Batch #:1000, training cost = 0.01484412606805563\n",
      "Batch #:1200, training cost = 0.0016639860114082694\n",
      "Batch #:1400, training cost = 0.0017385993851348758\n",
      "Batch #:1600, training cost = 0.0035247814375907183\n",
      "Batch #:1800, training cost = 0.00420363200828433\n",
      "Batch #:1941, training cost = 0.0023837611079216003\n",
      "\n",
      "******************\n",
      " Epoch =  71 \n",
      "\n",
      "Batch #:0, training cost = 0.009290087036788464\n",
      "Batch #:200, training cost = 0.008293547667562962\n",
      "Batch #:400, training cost = 0.0017977451207116246\n",
      "Batch #:600, training cost = 0.006140542682260275\n",
      "Batch #:800, training cost = 0.002819524612277746\n",
      "Batch #:1000, training cost = 0.004253131803125143\n",
      "Batch #:1200, training cost = 0.0015919586876407266\n",
      "Batch #:1400, training cost = 0.0028564478270709515\n",
      "Batch #:1600, training cost = 0.0019887094385921955\n",
      "Batch #:1800, training cost = 0.0022302460856735706\n",
      "Batch #:1941, training cost = 0.0005214951816014946\n",
      "\n",
      "******************\n",
      " Epoch =  72 \n",
      "\n",
      "Batch #:0, training cost = 0.0019637802615761757\n",
      "Batch #:200, training cost = 0.0014510737964883447\n",
      "Batch #:400, training cost = 0.0038158358074724674\n",
      "Batch #:600, training cost = 0.00911699328571558\n",
      "Batch #:800, training cost = 0.005289142020046711\n",
      "Batch #:1000, training cost = 0.004844989161938429\n",
      "Batch #:1200, training cost = 0.004688166547566652\n",
      "Batch #:1400, training cost = 0.00872228667140007\n",
      "Batch #:1600, training cost = 0.0015831653727218509\n",
      "Batch #:1800, training cost = 0.0008493769564665854\n",
      "Batch #:1941, training cost = 0.0019698815885931253\n",
      "\n",
      "******************\n",
      " Epoch =  73 \n",
      "\n",
      "Batch #:0, training cost = 0.01705470308661461\n",
      "Batch #:200, training cost = 0.010246897116303444\n",
      "Batch #:400, training cost = 0.004519023932516575\n",
      "Batch #:600, training cost = 0.0008673498523421586\n",
      "Batch #:800, training cost = 0.0011456935899332166\n",
      "Batch #:1000, training cost = 0.004676102194935083\n",
      "Batch #:1200, training cost = 0.0071429600939154625\n",
      "Batch #:1400, training cost = 0.0010682677384465933\n",
      "Batch #:1600, training cost = 0.004181044641882181\n",
      "Batch #:1800, training cost = 0.0008238438749685884\n",
      "Batch #:1941, training cost = 0.004963757935911417\n",
      "\n",
      "******************\n",
      " Epoch =  74 \n",
      "\n",
      "Batch #:0, training cost = 0.001110946061089635\n",
      "Batch #:200, training cost = 0.01163101103156805\n",
      "Batch #:400, training cost = 0.00463328929618001\n",
      "Batch #:600, training cost = 0.0004691916692536324\n",
      "Batch #:800, training cost = 0.001508402405306697\n",
      "Batch #:1000, training cost = 0.0035469343420118093\n",
      "Batch #:1200, training cost = 0.005082665476948023\n",
      "Batch #:1400, training cost = 0.00983581691980362\n",
      "Batch #:1600, training cost = 0.0017161121359094977\n",
      "Batch #:1800, training cost = 0.005053482484072447\n",
      "Batch #:1941, training cost = 0.007240144070237875\n",
      "\n",
      "******************\n",
      " Epoch =  75 \n",
      "\n",
      "Batch #:0, training cost = 0.008866973221302032\n",
      "Batch #:200, training cost = 0.01115372683852911\n",
      "Batch #:400, training cost = 0.000728535174857825\n",
      "Batch #:600, training cost = 0.0026486306451261044\n",
      "Batch #:800, training cost = 0.001456746133044362\n",
      "Batch #:1000, training cost = 0.003259222721680999\n",
      "Batch #:1200, training cost = 0.005139304790645838\n",
      "Batch #:1400, training cost = 0.008261640556156635\n",
      "Batch #:1600, training cost = 0.0071174693293869495\n",
      "Batch #:1800, training cost = 0.0019862831104546785\n",
      "Batch #:1941, training cost = 0.0003733501653186977\n",
      "\n",
      "******************\n",
      " Epoch =  76 \n",
      "\n",
      "Batch #:0, training cost = 0.0013229625765234232\n",
      "Batch #:200, training cost = 0.015103437006473541\n",
      "Batch #:400, training cost = 0.010914196260273457\n",
      "Batch #:600, training cost = 0.0017821738729253411\n",
      "Batch #:800, training cost = 0.0024902201257646084\n",
      "Batch #:1000, training cost = 0.0018071966478601098\n",
      "Batch #:1200, training cost = 0.0023432611487805843\n",
      "Batch #:1400, training cost = 0.008474329486489296\n",
      "Batch #:1600, training cost = 0.0027876924723386765\n",
      "Batch #:1800, training cost = 0.0013062661746516824\n",
      "Batch #:1941, training cost = 0.006692640017718077\n",
      "\n",
      "******************\n",
      " Epoch =  77 \n",
      "\n",
      "Batch #:0, training cost = 0.005399241577833891\n",
      "Batch #:200, training cost = 0.00382302887737751\n",
      "Batch #:400, training cost = 0.0028103350196033716\n",
      "Batch #:600, training cost = 0.009768983349204063\n",
      "Batch #:800, training cost = 0.0034368063788861036\n",
      "Batch #:1000, training cost = 0.004075204022228718\n",
      "Batch #:1200, training cost = 0.0009118642774410546\n",
      "Batch #:1400, training cost = 0.0008874921477399766\n",
      "Batch #:1600, training cost = 0.012821183539927006\n",
      "Batch #:1800, training cost = 0.005045882426202297\n",
      "Batch #:1941, training cost = 0.001633054343983531\n",
      "\n",
      "******************\n",
      " Epoch =  78 \n",
      "\n",
      "Batch #:0, training cost = 0.0023760946933180094\n",
      "Batch #:200, training cost = 0.005367240868508816\n",
      "Batch #:400, training cost = 0.005984557326883078\n",
      "Batch #:600, training cost = 0.014803526923060417\n",
      "Batch #:800, training cost = 0.007355662528425455\n",
      "Batch #:1000, training cost = 0.0028320702258497477\n",
      "Batch #:1200, training cost = 0.0029541384428739548\n",
      "Batch #:1400, training cost = 0.007957467809319496\n",
      "Batch #:1600, training cost = 0.0031215972267091274\n",
      "Batch #:1800, training cost = 0.0030281920917332172\n",
      "Batch #:1941, training cost = 0.0008389638969674706\n",
      "\n",
      "******************\n",
      " Epoch =  79 \n",
      "\n",
      "Batch #:0, training cost = 0.001101418281905353\n",
      "Batch #:200, training cost = 0.001018742797896266\n",
      "Batch #:400, training cost = 0.0033383865375071764\n",
      "Batch #:600, training cost = 0.008191293105483055\n",
      "Batch #:800, training cost = 0.002448335289955139\n",
      "Batch #:1000, training cost = 0.004886916372925043\n",
      "Batch #:1200, training cost = 0.0011415539775043726\n",
      "Batch #:1400, training cost = 0.0010485831880941987\n",
      "Batch #:1600, training cost = 0.004419264383614063\n",
      "Batch #:1800, training cost = 0.0016512259608134627\n",
      "Batch #:1941, training cost = 0.011552547104656696\n",
      "\n",
      "******************\n",
      " Epoch =  80 \n",
      "\n",
      "Batch #:0, training cost = 0.015370725654065609\n",
      "Batch #:200, training cost = 0.0028074015863239765\n",
      "Batch #:400, training cost = 0.0020316115114837885\n",
      "Batch #:600, training cost = 0.004288799595087767\n",
      "Batch #:800, training cost = 0.002107667038217187\n",
      "Batch #:1000, training cost = 0.0011605400359258056\n",
      "Batch #:1200, training cost = 0.0018502649618312716\n",
      "Batch #:1400, training cost = 0.00320133613422513\n",
      "Batch #:1600, training cost = 0.0006897175335325301\n",
      "Batch #:1800, training cost = 0.002627258887514472\n",
      "Batch #:1941, training cost = 0.005625058431178331\n",
      "\n",
      "******************\n",
      " Epoch =  81 \n",
      "\n",
      "Batch #:0, training cost = 0.01095921453088522\n",
      "Batch #:200, training cost = 0.0026149193290621042\n",
      "Batch #:400, training cost = 0.00654152175411582\n",
      "Batch #:600, training cost = 0.0013255624799057841\n",
      "Batch #:800, training cost = 0.011754295788705349\n",
      "Batch #:1000, training cost = 0.002589448122307658\n",
      "Batch #:1200, training cost = 0.003732145531103015\n",
      "Batch #:1400, training cost = 0.003541146172210574\n",
      "Batch #:1600, training cost = 0.0007027494721114635\n",
      "Batch #:1800, training cost = 0.0020123282447457314\n",
      "Batch #:1941, training cost = 0.0047364020720124245\n",
      "\n",
      "******************\n",
      " Epoch =  82 \n",
      "\n",
      "Batch #:0, training cost = 0.003334686392918229\n",
      "Batch #:200, training cost = 0.0016551305307075381\n",
      "Batch #:400, training cost = 0.0008748169057071209\n",
      "Batch #:600, training cost = 0.0014325336087495089\n",
      "Batch #:800, training cost = 0.0060774716548621655\n",
      "Batch #:1000, training cost = 0.0009490582742728293\n",
      "Batch #:1200, training cost = 0.009594897739589214\n",
      "Batch #:1400, training cost = 0.0002971717622131109\n",
      "Batch #:1600, training cost = 0.003465470392256975\n",
      "Batch #:1800, training cost = 0.0002644867345225066\n",
      "Batch #:1941, training cost = 0.004947155714035034\n",
      "\n",
      "******************\n",
      " Epoch =  83 \n",
      "\n",
      "Batch #:0, training cost = 0.001886487938463688\n",
      "Batch #:200, training cost = 0.0060586584731936455\n",
      "Batch #:400, training cost = 0.006912179756909609\n",
      "Batch #:600, training cost = 0.0011473679915070534\n",
      "Batch #:800, training cost = 0.007486401591449976\n",
      "Batch #:1000, training cost = 0.0011416868073865771\n",
      "Batch #:1200, training cost = 0.0021432151552289724\n",
      "Batch #:1400, training cost = 0.00207018805667758\n",
      "Batch #:1600, training cost = 0.0061409613117575645\n",
      "Batch #:1800, training cost = 0.004132665228098631\n",
      "Batch #:1941, training cost = 0.000577366619836539\n",
      "\n",
      "******************\n",
      " Epoch =  84 \n",
      "\n",
      "Batch #:0, training cost = 0.001469044596888125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #:200, training cost = 0.0010356655111536384\n",
      "Batch #:400, training cost = 0.009399237111210823\n",
      "Batch #:600, training cost = 0.007221837993711233\n",
      "Batch #:800, training cost = 0.0014807202387601137\n",
      "Batch #:1000, training cost = 0.005768573842942715\n",
      "Batch #:1200, training cost = 0.003623223165050149\n",
      "Batch #:1400, training cost = 0.0020630902145057917\n",
      "Batch #:1600, training cost = 0.0014951881021261215\n",
      "Batch #:1800, training cost = 0.0007463571382686496\n",
      "Batch #:1941, training cost = 0.0009778219973668456\n",
      "\n",
      "******************\n",
      " Epoch =  85 \n",
      "\n",
      "Batch #:0, training cost = 0.0028934055007994175\n",
      "Batch #:200, training cost = 0.010765129700303078\n",
      "Batch #:400, training cost = 0.009211628697812557\n",
      "Batch #:600, training cost = 0.0008244792115874588\n",
      "Batch #:800, training cost = 0.0022671481128782034\n",
      "Batch #:1000, training cost = 0.00046362497960217297\n",
      "Batch #:1200, training cost = 0.001881999894976616\n",
      "Batch #:1400, training cost = 0.00250605633482337\n",
      "Batch #:1600, training cost = 0.001042789313942194\n",
      "Batch #:1800, training cost = 0.00028287089662626386\n",
      "Batch #:1941, training cost = 0.002656528726220131\n",
      "\n",
      "******************\n",
      " Epoch =  86 \n",
      "\n",
      "Batch #:0, training cost = 0.0043105739168822765\n",
      "Batch #:200, training cost = 0.01003567036241293\n",
      "Batch #:400, training cost = 0.006678671110421419\n",
      "Batch #:600, training cost = 0.0006789317703805864\n",
      "Batch #:800, training cost = 0.0012893711682409048\n",
      "Batch #:1000, training cost = 0.0006367976893670857\n",
      "Batch #:1200, training cost = 0.001512717455625534\n",
      "Batch #:1400, training cost = 0.0013554480392485857\n",
      "Batch #:1600, training cost = 0.007832148112356663\n",
      "Batch #:1800, training cost = 0.0020859704818576574\n",
      "Batch #:1941, training cost = 0.0036477576941251755\n",
      "\n",
      "******************\n",
      " Epoch =  87 \n",
      "\n",
      "Batch #:0, training cost = 0.005071504507213831\n",
      "Batch #:200, training cost = 0.005164151545614004\n",
      "Batch #:400, training cost = 0.0045808530412614346\n",
      "Batch #:600, training cost = 0.0005346965044736862\n",
      "Batch #:800, training cost = 0.002017334569245577\n",
      "Batch #:1000, training cost = 0.004246510099619627\n",
      "Batch #:1200, training cost = 0.00043697902583517134\n",
      "Batch #:1400, training cost = 0.0031297095119953156\n",
      "Batch #:1600, training cost = 0.0031753804069012403\n",
      "Batch #:1800, training cost = 0.003302730619907379\n",
      "Batch #:1941, training cost = 0.0013066073879599571\n",
      "\n",
      "******************\n",
      " Epoch =  88 \n",
      "\n",
      "Batch #:0, training cost = 0.0005583169986493886\n",
      "Batch #:200, training cost = 0.001496514305472374\n",
      "Batch #:400, training cost = 0.0016057800967246294\n",
      "Batch #:600, training cost = 0.0040013473480939865\n",
      "Batch #:800, training cost = 0.0005002477555535734\n",
      "Batch #:1000, training cost = 0.0011523568537086248\n",
      "Batch #:1200, training cost = 0.0013085843529552221\n",
      "Batch #:1400, training cost = 0.0006417024997062981\n",
      "Batch #:1600, training cost = 0.0018258104100823402\n",
      "Batch #:1800, training cost = 0.0007803916814737022\n",
      "Batch #:1941, training cost = 0.012733257375657558\n",
      "\n",
      "******************\n",
      " Epoch =  89 \n",
      "\n",
      "Batch #:0, training cost = 0.012182396836578846\n",
      "Batch #:200, training cost = 0.004479690920561552\n",
      "Batch #:400, training cost = 0.002081469399854541\n",
      "Batch #:600, training cost = 0.001901260344311595\n",
      "Batch #:800, training cost = 0.0010889729019254446\n",
      "Batch #:1000, training cost = 0.0009592440910637379\n",
      "Batch #:1200, training cost = 0.0010483221849426627\n",
      "Batch #:1400, training cost = 0.0005711017875000834\n",
      "Batch #:1600, training cost = 0.004866305273026228\n",
      "Batch #:1800, training cost = 0.001281378441490233\n",
      "Batch #:1941, training cost = 0.0032944318372756243\n",
      "\n",
      "******************\n",
      " Epoch =  90 \n",
      "\n",
      "Batch #:0, training cost = 0.002405371516942978\n",
      "Batch #:200, training cost = 0.0016308429185301065\n",
      "Batch #:400, training cost = 0.004699141718447208\n",
      "Batch #:600, training cost = 0.0035909584257751703\n",
      "Batch #:800, training cost = 0.0006749406456947327\n",
      "Batch #:1000, training cost = 0.008166651241481304\n",
      "Batch #:1200, training cost = 0.004822383634746075\n",
      "Batch #:1400, training cost = 0.0035758954472839832\n",
      "Batch #:1600, training cost = 0.00238816044293344\n",
      "Batch #:1800, training cost = 0.00046560028567910194\n",
      "Batch #:1941, training cost = 0.0017598702106624842\n",
      "\n",
      "******************\n",
      " Epoch =  91 \n",
      "\n",
      "Batch #:0, training cost = 0.0014673967380076647\n",
      "Batch #:200, training cost = 0.0004714836832135916\n",
      "Batch #:400, training cost = 0.002678485121577978\n",
      "Batch #:600, training cost = 0.0006977696903049946\n",
      "Batch #:800, training cost = 0.0011475945357233286\n",
      "Batch #:1000, training cost = 0.0011340182973071933\n",
      "Batch #:1200, training cost = 0.0030427591409534216\n",
      "Batch #:1400, training cost = 0.0015084241749718785\n",
      "Batch #:1600, training cost = 0.0010526046389713883\n",
      "Batch #:1800, training cost = 0.009826661087572575\n",
      "Batch #:1941, training cost = 0.0014548453036695719\n",
      "\n",
      "******************\n",
      " Epoch =  92 \n",
      "\n",
      "Batch #:0, training cost = 0.0010347043862566352\n",
      "Batch #:200, training cost = 0.0012033091625198722\n",
      "Batch #:400, training cost = 0.001461194478906691\n",
      "Batch #:600, training cost = 0.002706731902435422\n",
      "Batch #:800, training cost = 0.001721905660815537\n",
      "Batch #:1000, training cost = 0.0023029416333884\n",
      "Batch #:1200, training cost = 0.001651824451982975\n",
      "Batch #:1400, training cost = 0.0029108398593962193\n",
      "Batch #:1600, training cost = 0.001132464618422091\n",
      "Batch #:1800, training cost = 0.00250048004090786\n",
      "Batch #:1941, training cost = 0.00709616020321846\n",
      "\n",
      "******************\n",
      " Epoch =  93 \n",
      "\n",
      "Batch #:0, training cost = 0.004423745907843113\n",
      "Batch #:200, training cost = 0.00933388713747263\n",
      "Batch #:400, training cost = 0.0018241526558995247\n",
      "Batch #:600, training cost = 0.006797038950026035\n",
      "Batch #:800, training cost = 0.003248160472139716\n",
      "Batch #:1000, training cost = 0.0009199926862493157\n",
      "Batch #:1200, training cost = 0.004543893504887819\n",
      "Batch #:1400, training cost = 0.0012471525697037578\n",
      "Batch #:1600, training cost = 0.0013272537617012858\n",
      "Batch #:1800, training cost = 0.02917429618537426\n",
      "Batch #:1941, training cost = 0.002103937789797783\n",
      "\n",
      "******************\n",
      " Epoch =  94 \n",
      "\n",
      "Batch #:0, training cost = 0.00463098892942071\n",
      "Batch #:200, training cost = 0.011522009037435055\n",
      "Batch #:400, training cost = 0.0011244344059377909\n",
      "Batch #:600, training cost = 0.008356798440217972\n",
      "Batch #:800, training cost = 0.0005739688640460372\n",
      "Batch #:1000, training cost = 0.0006296637584455311\n",
      "Batch #:1200, training cost = 0.008237236179411411\n",
      "Batch #:1400, training cost = 0.0028790724463760853\n",
      "Batch #:1600, training cost = 0.0015042355516925454\n",
      "Batch #:1800, training cost = 0.001033106935210526\n",
      "Batch #:1941, training cost = 0.0008565642056055367\n",
      "\n",
      "******************\n",
      " Epoch =  95 \n",
      "\n",
      "Batch #:0, training cost = 0.003342281561344862\n",
      "Batch #:200, training cost = 0.0006876177503727376\n",
      "Batch #:400, training cost = 0.0007867459789849818\n",
      "Batch #:600, training cost = 0.0006016819970682263\n",
      "Batch #:800, training cost = 0.0012765767751261592\n",
      "Batch #:1000, training cost = 0.0008951138588599861\n",
      "Batch #:1200, training cost = 0.001193832722492516\n",
      "Batch #:1400, training cost = 0.0029971066396683455\n",
      "Batch #:1600, training cost = 0.0008899802342057228\n",
      "Batch #:1800, training cost = 0.0013616661308333278\n",
      "Batch #:1941, training cost = 0.0003962709160987288\n",
      "\n",
      "******************\n",
      " Epoch =  96 \n",
      "\n",
      "Batch #:0, training cost = 0.0015175195876508951\n",
      "Batch #:200, training cost = 0.0025503267534077168\n",
      "Batch #:400, training cost = 0.0034641940146684647\n",
      "Batch #:600, training cost = 0.0006515749846585095\n",
      "Batch #:800, training cost = 0.000277424871455878\n",
      "Batch #:1000, training cost = 0.0017489418387413025\n",
      "Batch #:1200, training cost = 0.0042689791880548\n",
      "Batch #:1400, training cost = 0.012841874733567238\n",
      "Batch #:1600, training cost = 0.005572831723839045\n",
      "Batch #:1800, training cost = 0.0037908214144408703\n",
      "Batch #:1941, training cost = 0.007595844566822052\n",
      "\n",
      "******************\n",
      " Epoch =  97 \n",
      "\n",
      "Batch #:0, training cost = 0.004224731586873531\n",
      "Batch #:200, training cost = 0.0073271444998681545\n",
      "Batch #:400, training cost = 0.003733397927135229\n",
      "Batch #:600, training cost = 0.01788865588605404\n",
      "Batch #:800, training cost = 0.005871692206710577\n",
      "Batch #:1000, training cost = 0.005205309949815273\n",
      "Batch #:1200, training cost = 0.0037835887633264065\n",
      "Batch #:1400, training cost = 0.004345300607383251\n",
      "Batch #:1600, training cost = 0.0017818693304434419\n",
      "Batch #:1800, training cost = 0.00028999027563259006\n",
      "Batch #:1941, training cost = 0.001191208022646606\n",
      "\n",
      "******************\n",
      " Epoch =  98 \n",
      "\n",
      "Batch #:0, training cost = 0.000464810203993693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #:200, training cost = 0.0032806829549372196\n",
      "Batch #:400, training cost = 0.0013825384667143226\n",
      "Batch #:600, training cost = 0.0030412061605602503\n",
      "Batch #:800, training cost = 0.0007839394966140389\n",
      "Batch #:1000, training cost = 0.0005462670815177262\n",
      "Batch #:1200, training cost = 0.002419086406007409\n",
      "Batch #:1400, training cost = 0.0016834094421938062\n",
      "Batch #:1600, training cost = 0.0005589540232904255\n",
      "Batch #:1800, training cost = 0.0032788687385618687\n",
      "Batch #:1941, training cost = 0.0013830476673319936\n",
      "\n",
      "******************\n",
      " Epoch =  99 \n",
      "\n",
      "Batch #:0, training cost = 0.003833186347037554\n",
      "Batch #:200, training cost = 0.009618292562663555\n",
      "Batch #:400, training cost = 0.003160465508699417\n",
      "Batch #:600, training cost = 0.0016678154934197664\n",
      "Batch #:800, training cost = 0.0019480297341942787\n",
      "Batch #:1000, training cost = 0.001072492334060371\n",
      "Batch #:1200, training cost = 0.0005508613539859653\n",
      "Batch #:1400, training cost = 0.00044623849680647254\n",
      "Batch #:1600, training cost = 0.004194817505776882\n",
      "Batch #:1800, training cost = 0.0008767002145759761\n",
      "Batch #:1941, training cost = 0.0019807417411357164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model over a few epochs\n",
    "for epoch in range(num_epochs):\n",
    "    #np.random.shuffle(key_list)\n",
    "    print(\"\\n******************\\n Epoch = \", epoch,\"\\n\")\n",
    "    for j in range(num_batches):\n",
    "        mini_batch_index_start = j*minibatch_size\n",
    "        mini_batch_index_end = (j+1)*minibatch_size\n",
    "        batch_image_index = key_list[mini_batch_index_start:mini_batch_index_end ]\n",
    "        #print(j, mini_batch_index_start)\n",
    "        \n",
    "        # Generate mini-batch data and labels\n",
    "        for k in range(minibatch_size):\n",
    "            img_id = key_list[mini_batch_index_start + k]\n",
    "            batch_data[k,:] = torch.tensor(image_feature_dict[img_id], dtype= torch.float32)\n",
    "            labels = torch.tensor(labels_dict[img_id], dtype= torch.float32)\n",
    "            batch_labels[k, :] = labels\n",
    "        \n",
    "        #print(img_id)\n",
    "        if cuda_present:\n",
    "            batch_data = batch_data.cuda()\n",
    "            batch_labels = batch_labels.cuda()\n",
    "            \n",
    "        # clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward propogation\n",
    "        output_batch = model.forward(batch_data)\n",
    "\n",
    "        #calculate the loss\n",
    "        loss = criterion(output_batch,batch_labels)\n",
    "        \n",
    "        # backward propogation\n",
    "        loss.backward()\n",
    "        \n",
    "        # performs parameter updates using calculated gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        #cost = loss.item()\n",
    "        #print(cost)\n",
    "        # print statistics\n",
    "        \n",
    "        '''\n",
    "        for param in model.fc1.parameters():\n",
    "            for k in range(len(param.size())):\n",
    "                print(param[k])\n",
    "        ''' \n",
    "        if ( (j%200 ==0) or ((j+1)% num_batches ==0) ):\n",
    "            cost = loss.item()\n",
    "            #cost = cost.cpu()\n",
    "            print('Batch #:' + str(j) + \", training cost = \" + str(cost))\n",
    "key_list[0] \n",
    "labels_dict[img_id].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = {'epoch':100, 'state_dict':model.state_dict(), 'optim_dict':optimizer.state_dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(cur_dir, 'models/Inception_V3_R1/epoch100.pth.tar')\n",
    "torch.save(state, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bony/Deep_Learning_Stanford_CS230/Project/Code\n",
      "/home/bony/Deep_Learning_Stanford_CS230/Project/Data/train\n",
      "train\n",
      "datatype is train\n",
      "image id count =  31072\n",
      "image count =  0 0.00017762184143066406\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inception_v3_eval = inception_v3.eval()\n",
    "image_feature_dict = {}\n",
    "image_dict = data_loader.load_data(\"train\", params)\n",
    "img_count = 0\n",
    "t0 = time.time()\n",
    "for img_id in image_dict:\n",
    "    if (img_count %50 == 0):\n",
    "        t1 = time.time()\n",
    "        print(\"image count = \", img_count, t1-t0)\n",
    "        t0 = t1\n",
    "    input_img = data_loader.load_single_image(\"train\", params, img_id)\n",
    "    inception_v3_eval_out = inception_v3_eval(input_img)\n",
    "    image_feature_dict[img_id] = inception_v3_eval_out\n",
    "\n",
    "    img_count += 1\n",
    "\n",
    "print(\"Finished evaluation, next step is to save the data to file\")\n",
    "\n",
    "\n",
    "key_list = []\n",
    "for item in image_feature_dict:\n",
    "    key_list.append(item)\n",
    "f = open(\"image_resize299_inception_v3_feature.txt\", \"w\")\n",
    "for item in key_list:\n",
    "    val = str(image_feature_dict[item].tolist())\n",
    "    f.write(item+\":\"+val+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2885e+04 1.2540e+03 3.6210e+03 1.5610e+03 1.8580e+03 2.5130e+03\n",
      " 1.0080e+03 2.8220e+03 5.3000e+01 4.5000e+01 2.8000e+01 1.0930e+03\n",
      " 6.8800e+02 5.3700e+02 1.0660e+03 2.1000e+01 5.3000e+02 2.1000e+02\n",
      " 9.0200e+02 1.4820e+03 1.7200e+02 3.7770e+03 8.0200e+02 2.9650e+03\n",
      " 3.2200e+02 8.2280e+03 3.2800e+02 1.1000e+01]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAGsCAYAAAArGH/IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5bfd44780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target labels\n",
    "LABEL_MAP = {\n",
    "    0: \"Nucleoplasm\",\n",
    "    1: \"Nuclear membrane\",\n",
    "    2: \"Nucleoli\",\n",
    "    3: \"Nucleoli fibrillar center\",   \n",
    "    4: \"Nuclear speckles\",\n",
    "    5: \"Nuclear bodies\",\n",
    "    6: \"Endoplasmic reticulum\",\n",
    "    7: \"Golgi apparatus\",\n",
    "    8: \"Peroxisomes\",\n",
    "    9:  \"Endosomes\",\n",
    "    10: \"Lysosomes\",\n",
    "    11: \"Intermediate filaments\", \n",
    "    12: \"Actin filaments\",\n",
    "    13: \"Focal adhesion sites\",\n",
    "    14: \"Microtubules\",\n",
    "    15: \"Microtubule ends\",\n",
    "    16: \"Cytokinetic bridge\",\n",
    "    17: \"Mitotic spindle\",\n",
    "    18: \"Microtubule organizing center\",  \n",
    "    19: \"Centrosome\",\n",
    "    20: \"Lipid droplets\",\n",
    "    21: \"Plasma membrane\",\n",
    "    22: \"Cell junctions\",\n",
    "    23: \"Mitochondria\",\n",
    "    24: \"Aggresome\",\n",
    "    25: \"Cytosol\",\n",
    "    26: \"Cytoplasmic bodies\",\n",
    "    27: \"Rods & rings\"\n",
    "}\n",
    "\n",
    "# Defines\n",
    "DIM_HEIGHT = DIM_WIDTH = 512\n",
    "N_CHANNELS = 4\n",
    "\n",
    "label = np.zeros((28))\n",
    "for j in range(len(labels_dict)):\n",
    "    item = key_list[j]\n",
    "    tgt_label = labels_dict[item]\n",
    "    label += tgt_label\n",
    "    \n",
    "print(label)\n",
    "xx = list(LABEL_MAP.values())\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "mpl.style.use('seaborn-darkgrid')\n",
    "sns.barplot(x = label, y = xx)\n",
    "plt.title('Target Occurences', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rsbandhu\\\\Documents\\\\MUSTBACKUP\\\\Details\\\\Computers\\\\DeepLearning_Stanford_CS230\\\\Project\\\\all\\\\train'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.train_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating the model and initializing the weights from my laptop, downloaded from the torch sitem the local machine. Don't need this now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'VGG' has no attribute 'vgg19_bn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1c1dac4bbd3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVGG19_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGG\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#from models import vgg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvgg19_bn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg19_bn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcurdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvgg_dict_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models/VGG19_1/vgg19_bn-c79401a0.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'VGG' has no attribute 'vgg19_bn'"
     ]
    }
   ],
   "source": [
    "from models.VGG19_1.vgg import VGG\n",
    "#from models import vgg\n",
    "vgg19_bn = VGG.vgg19_bn(pretrained=False)\n",
    "curdir = os.getcwd()\n",
    "vgg_dict_path = os.path.join(curdir, \"models/VGG19_1/vgg19_bn-c79401a0.pth\")\n",
    "model_vgg19_bn.load_state_dict(torch.load(vgg_dict_path))\n",
    "\n",
    "for param in model_vgg19_bn.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['features.0.weight', 'features.0.bias', 'features.1.weight', 'features.1.bias', 'features.1.running_mean', 'features.1.running_var', 'features.3.weight', 'features.3.bias', 'features.4.weight', 'features.4.bias', 'features.4.running_mean', 'features.4.running_var', 'features.7.weight', 'features.7.bias', 'features.8.weight', 'features.8.bias', 'features.8.running_mean', 'features.8.running_var', 'features.10.weight', 'features.10.bias', 'features.11.weight', 'features.11.bias', 'features.11.running_mean', 'features.11.running_var', 'features.14.weight', 'features.14.bias', 'features.15.weight', 'features.15.bias', 'features.15.running_mean', 'features.15.running_var', 'features.17.weight', 'features.17.bias', 'features.18.weight', 'features.18.bias', 'features.18.running_mean', 'features.18.running_var', 'features.20.weight', 'features.20.bias', 'features.21.weight', 'features.21.bias', 'features.21.running_mean', 'features.21.running_var', 'features.23.weight', 'features.23.bias', 'features.24.weight', 'features.24.bias', 'features.24.running_mean', 'features.24.running_var', 'features.27.weight', 'features.27.bias', 'features.28.weight', 'features.28.bias', 'features.28.running_mean', 'features.28.running_var', 'features.30.weight', 'features.30.bias', 'features.31.weight', 'features.31.bias', 'features.31.running_mean', 'features.31.running_var', 'features.33.weight', 'features.33.bias', 'features.34.weight', 'features.34.bias', 'features.34.running_mean', 'features.34.running_var', 'features.36.weight', 'features.36.bias', 'features.37.weight', 'features.37.bias', 'features.37.running_mean', 'features.37.running_var', 'features.40.weight', 'features.40.bias', 'features.41.weight', 'features.41.bias', 'features.41.running_mean', 'features.41.running_var', 'features.43.weight', 'features.43.bias', 'features.44.weight', 'features.44.bias', 'features.44.running_mean', 'features.44.running_var', 'features.46.weight', 'features.46.bias', 'features.47.weight', 'features.47.bias', 'features.47.running_mean', 'features.47.running_var', 'features.49.weight', 'features.49.bias', 'features.50.weight', 'features.50.bias', 'features.50.running_mean', 'features.50.running_var', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias', 'classifier.6.weight', 'classifier.6.bias'])\n",
      "odict_keys(['0.weight', '0.bias', '1.weight', '1.bias', '1.running_mean', '1.running_var', '3.weight', '3.bias', '4.weight', '4.bias', '4.running_mean', '4.running_var', '7.weight', '7.bias', '8.weight', '8.bias', '8.running_mean', '8.running_var', '10.weight', '10.bias', '11.weight', '11.bias', '11.running_mean', '11.running_var', '14.weight', '14.bias', '15.weight', '15.bias', '15.running_mean', '15.running_var', '17.weight', '17.bias', '18.weight', '18.bias', '18.running_mean', '18.running_var', '20.weight', '20.bias', '21.weight', '21.bias', '21.running_mean', '21.running_var', '23.weight', '23.bias', '24.weight', '24.bias', '24.running_mean', '24.running_var', '27.weight', '27.bias', '28.weight', '28.bias', '28.running_mean', '28.running_var', '30.weight', '30.bias', '31.weight', '31.bias', '31.running_mean', '31.running_var', '33.weight', '33.bias', '34.weight', '34.bias', '34.running_mean', '34.running_var', '36.weight', '36.bias', '37.weight', '37.bias', '37.running_mean', '37.running_var', '40.weight', '40.bias', '41.weight', '41.bias', '41.running_mean', '41.running_var', '43.weight', '43.bias', '44.weight', '44.bias', '44.running_mean', '44.running_var', '46.weight', '46.bias', '47.weight', '47.bias', '47.running_mean', '47.running_var', '49.weight', '49.bias', '50.weight', '50.bias', '50.running_mean', '50.running_var'])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys(['weight', 'bias', 'running_mean', 'running_var'])\n",
      "odict_keys([])\n",
      "odict_keys([])\n",
      "odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias'])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys([])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys([])\n",
      "odict_keys([])\n",
      "odict_keys(['weight', 'bias'])\n",
      "odict_keys([])\n"
     ]
    }
   ],
   "source": [
    "for x in model_vgg19_bn.classifier.children():\n",
    "    print(x)\n",
    "    for y in x.parameters():\n",
    "        print(y.requires_grad)\n",
    "for x in model_vgg19_bn.modules():\n",
    "    print(x.state_dict().keys())\n",
    "import json\n",
    "cur_dir = os.getcwd()\n",
    "print(cur_dir)\n",
    "json_path = os.path.join(cur_dir,'models\\params.json')\n",
    "f = open(json_path)\n",
    "params = json.load(f)\n",
    "#params = utils.Params(json_path)\n",
    "data_loader = Dataloader(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050 Ti'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bony/Deep_Learning_Stanford_CS230/Project/Code'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bony/Deep_Learning_Stanford_CS230/Project/Code'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.Inception_V3_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
